{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvTranspose2D_examples.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camulro/Aprendizaje-II/blob/sesi%C3%B3n2/ConvTranspose2D_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WndRPSUqP9nN"
      },
      "source": [
        "# ConvTranspose2D examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LdsrymqP7vI"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZq_ZF_Rs2K"
      },
      "source": [
        "# Syntax:\n",
        "# torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, \n",
        "#groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)\n",
        "\n",
        "# Input: (N,Cin,Hin,Win)\n",
        "# Output: (N,Cout, Hout, Wout)\n",
        "\n",
        "# Donde:\n",
        "# Hout=(Hin−1)×stride[0]−2×padding[0]+dilation[0]×(kernel_size[0]−1)+output_padding[0]+1\n",
        "# Wout=(Win−1)×stride[1]−2×padding[1]+dilation[1]×(kernel_size[1]−1)+output_padding[1]+1\n",
        "# N tamaño del batch\n",
        "\n",
        "# Convertir de 16 canales a 33 usando un kernel cuadrado 3x3, stride=2 y sin padding\n",
        "m = nn.ConvTranspose2d( ...\n",
        "# La misma conversión pero con kernel rectangular: H=3, W=5, stride asimétrico (2 en H y 1 en W) y padding asimétrico (4 en H y 2 en W)\n",
        "m2 = nn.ConvTranspose2d( ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyfnVfbSQMXO"
      },
      "source": [
        "# Definir un tensor de entrada random\n",
        "input = torch.randn(20,16,50,100)\n",
        "# Visualizar con print las dimensiones de salida de ambas convoluciones transpuestas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ew-Lb3GZItw"
      },
      "source": [
        "Vamos a ver el efecto de especificar las dimensiones de salida mediante el parámetro output_size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_2-44ImQHlM"
      },
      "source": [
        "# Primero define un tensor random de 16 canales e imágenes de  H=12, W=12\n",
        "input = torch.randn( ...\n",
        "# define dos capas Conv2d/ConvTranspose2d que mantengan el nº de canales en 16, kernel 3x3, stride=2 y padding=1\n",
        "downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1)\n",
        "upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBqMRmMPS-9I"
      },
      "source": [
        "# Submuestrea 'input' reduciendo sus dimensiones H y W mediante la capa downsample.\n",
        "# Observa con print las dimensiones del tensor obtenido. ¿Es el resultado esperado?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez5ka_pfQlVF"
      },
      "source": [
        "# Podremos ahora aplicar un upsample mediante la capa ConvTranspose2d definida anteriormente.\n",
        "# Realiza el upsample del tensor anterior submuestreado. ¿Obtenemos las dimensiones originales?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBkcTIkIY8RH"
      },
      "source": [
        "# Podemos ajustar las dimensiones de las features de salida con el parámetro output_size. \n",
        "# Haz el upsample de la salida anterior forzando a que tengamos el mismo tamaño de features de salida que de entrada.\n",
        "# Muestra las dimensiones del tensor obtenido ¿qué diferencia observas con el caso anterior?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs5fCcUOdeJB"
      },
      "source": [
        "# Repite el downsample y upsample ahora con un tensor de H=11, W=11. Oserva las dimensiones del tensor tras el upsample,\n",
        "# sin especificar y especificando el output_size. ¿Qué conclusiones extraes?"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}