{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "04-Pytorch-con-GPU-CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "laOv0FJc3xJW",
        "n2QOf-HEltUP"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camulro/Aprendizaje-II/blob/sesi%C3%B3n1/04_Pytorch_con_GPU_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqPW8adYjVJ"
      },
      "source": [
        "![IDAL](https://i.imgur.com/tIKXIG1.jpg)  \n",
        "\n",
        "#<strong>**Máster en Inteligencia Artificial Avanzada y Aplicada  IA^3**</strong>\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nH891SrsKDo"
      },
      "source": [
        "# Que es CUDA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRsotPs3sKDp"
      },
      "source": [
        "Mucha gente confunde CUDA con un lengaje o con una API. No lo es. Es más que eso. CUDA en una plataforma de cálculo computerizado paralelo y un modelo de programación que permite aprovechar las GPUs para tareas de propósito general de una forma fácil y elegante. Los desarrolladores pueden continuar trabajando en C, C++, Fortran, Python y una lista cada día más amplia e incorpora extensiones de estos lenguajes en forma de unas pocas palabras clave básicas.\n",
        "\n",
        "Estas palabras clave permiten al desarrollador expresar cantidades masivas de paralelismo y dirigir al compilador a la porción de la aplicación que se mapea a la GPU. En definitiva, hace que el acceso a la gran potencia computacional de las GPUs se haya incorporado en los lenguajes de programación de propósito general, permitiendo una gran expansión de técnicas y tecnologías que requieren de esa potencia, como las técnicas de aprensdizaje máquina, inteligencia artificial y más concretamente aprendizaje profundo (_deep learning_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4uAQv4usKDq"
      },
      "source": [
        "# Como instalo PyTorch para GPU?\n",
        "\n",
        "En primer lugar es necesario tener una tarjeta gráfica NVIDIA compatible y con los drivers CUDA instalado y actualizados correctamente.  A continuación selecciona la versión de Pytorch correspondiente al descargarlo de la [página oficial](https://pytorch.org/get-started/locally/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k_XKh24sKDq"
      },
      "source": [
        "# Como saber si tienes CUDA disponible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N57HhthQsKDr",
        "outputId": "3672f362-e8fe-4c12-ed05-f07118b40ff0"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "# True"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2a-td3HsKDt"
      },
      "source": [
        "# Usando GPU y CUDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hqUQGbFsKDu",
        "outputId": "ec54edb7-bd84-4127-8298-5243cac47d9a"
      },
      "source": [
        "## Id del dispositivo por defecto\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wZqoghwjsKDu",
        "outputId": "fa24c8ef-186e-4b43-8b20-41d19b9273d8"
      },
      "source": [
        "# 0\n",
        "torch.cuda.get_device_name(0) # Obtenemos el nombre del dispositivo ID '0'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFS_Uun6sKDv",
        "outputId": "5996beb0-255f-4de7-8dd8-b8d4cd52ff15"
      },
      "source": [
        "# Retorna el uso de memoria actual provocado por\n",
        "# tensores en bytes para el dispositivo dado\n",
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LegDTTgsKDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005696e8-adf8-4cdb-cef1-b191b977cf16"
      },
      "source": [
        "# Retorna la memoria gestionada por el gestor de memoria \n",
        "# en bytes para el dispositivo dado\n",
        "torch.cuda.memory_reserved()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AonHdnetsKDw"
      },
      "source": [
        "# Usando CUDA en lugar de CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGh82BAssKDx"
      },
      "source": [
        "# CPU\n",
        "a = torch.FloatTensor([1.,2.])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebe_6Q_MsKDx",
        "outputId": "ffb84ff2-6b0f-4e65-f467-753ae60b77c7"
      },
      "source": [
        "a"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b-QcGX2sKDy",
        "outputId": "f4a37a67-a816-4ebd-bfed-5053afe90613"
      },
      "source": [
        "a.device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRSaR12psKDy"
      },
      "source": [
        "# GPU\n",
        "a = torch.FloatTensor([1., 2.]).cuda() #lo genera en gpu directamente\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5UM3xf1sKDz",
        "outputId": "3e08904b-c22d-4bf9-922c-076626d920e0"
      },
      "source": [
        "a.device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19pJnecDsKDz",
        "outputId": "c1d4133c-fca8-477a-a7a1-e10bb4fd4802"
      },
      "source": [
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlRPFKFKsKD0"
      },
      "source": [
        "## Enviando modelos a la GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYDU7wJlsKD0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3VpD2TWB8qH"
      },
      "source": [
        "class Model(nn.Module): \n",
        "# Regresion logística\n",
        "    def __init__(self, input_size=4, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)\n",
        "        return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep0lWyRYsKD1"
      },
      "source": [
        "torch.manual_seed(32)\n",
        "model = Model()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQl9xu5WsKD1",
        "outputId": "609d6123-0d4f-4c16-c46e-e404daaec6f7"
      },
      "source": [
        "# Comprobación: discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda\n",
        "next(model.parameters()).is_cuda #comprobamos si los parámetros del modelo estan en cuda"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atjKSR4ysKD2"
      },
      "source": [
        "gpumodel = model.cuda()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTpWkxrvsKD2",
        "outputId": "674f6289-7771-4b99-ac82-781b1b6ae618"
      },
      "source": [
        "next(gpumodel.parameters()).is_cuda"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N0wH5ELaqGr",
        "outputId": "3bc4086e-6bff-4920-e76d-f00c4d166b5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyMLuJp4sKD3"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datos/iris.csv')\n",
        "X = df.drop('target',axis=1).values\n",
        "y = df['target'].values\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ncfpk5q_-WP1",
        "outputId": "5a547ea3-96ce-4d2c-b582-d3b3de073dc6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1af9085d-2b49-4f2b-a3c3-b2b1150ef17f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1af9085d-2b49-4f2b-a3c3-b2b1150ef17f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1af9085d-2b49-4f2b-a3c3-b2b1150ef17f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1af9085d-2b49-4f2b-a3c3-b2b1150ef17f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2     0.0\n",
              "1                4.9               3.0  ...               0.2     0.0\n",
              "2                4.7               3.2  ...               0.2     0.0\n",
              "3                4.6               3.1  ...               0.2     0.0\n",
              "4                5.0               3.6  ...               0.2     0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNmTedvcJYSP",
        "outputId": "ed719d32-a952-4efe-8eda-6545d8267795"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQYmDDbxCWpU"
      },
      "source": [
        "## Conjuntos Train-Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tSFdICA6KJs"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2G07_ypsKD3"
      },
      "source": [
        "## Convertir Tensores a .cuda() tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTAADv48sKD4"
      },
      "source": [
        "X_train = torch.FloatTensor(X_train).cuda()\n",
        "X_test = torch.FloatTensor(X_test).cuda()\n",
        "y_train = torch.LongTensor(y_train).cuda()\n",
        "y_test = torch.LongTensor(y_test).cuda()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgCVuGql_pCD"
      },
      "source": [
        "## Preparacion de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENmTJnbQsKD4"
      },
      "source": [
        "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
        "testloader = DataLoader(X_test, batch_size=60, shuffle=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXCKApAR_e2I"
      },
      "source": [
        "## Función de coste, optimizador y evaluador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adtAh-XVsKD4"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() #función de pérdida, clasificar entre 3 clases de planta -> entropia cruzada\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11hDOTR1fTTZ"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)) #devuelve el porcentaje total de predicciones acertadas"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDFh6ggH3s2H"
      },
      "source": [
        "## Entrenamiento con GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2quz2ARSsKD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372d968b-063f-4389-a954-489877d94e68"
      },
      "source": [
        "import time #para medir el tiempo\n",
        "epochs = 300\n",
        "losses = []\n",
        "accs =[]\n",
        "start = time.time() #tiempo inicial\n",
        "for i in range(epochs):\n",
        "    i+=1\n",
        "    y_pred = gpumodel.forward(X_train) #calcula regresión lineal\n",
        "    loss = criterion(y_pred, y_train) #perdidas\n",
        "    acc = accuracy(y_pred, y_train) #precisión\n",
        "    losses.append(loss)\n",
        "    accs.append(acc)\n",
        "    \n",
        "    # log:\n",
        "    if i%10 == 1: #en los múltiplos de 10 imprime:\n",
        "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}  acc: {acc.item():10.8f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "print(f'TOTAL TRAINING TIME: {time.time()-start}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1  loss: 0.26590708  acc: 0.96666664\n",
            "epoch: 11  loss: 0.25990745  acc: 0.96666664\n",
            "epoch: 21  loss: 0.25415474  acc: 0.96666664\n",
            "epoch: 31  loss: 0.24863632  acc: 0.96666664\n",
            "epoch: 41  loss: 0.24334060  acc: 0.96666664\n",
            "epoch: 51  loss: 0.23825659  acc: 0.96666664\n",
            "epoch: 61  loss: 0.23337373  acc: 0.96666664\n",
            "epoch: 71  loss: 0.22868247  acc: 0.96666664\n",
            "epoch: 81  loss: 0.22417334  acc: 0.96666664\n",
            "epoch: 91  loss: 0.21983761  acc: 0.96666664\n",
            "epoch: 101  loss: 0.21566698  acc: 0.96666664\n",
            "epoch: 111  loss: 0.21165358  acc: 0.96666664\n",
            "epoch: 121  loss: 0.20778990  acc: 0.96666664\n",
            "epoch: 131  loss: 0.20406890  acc: 0.96666664\n",
            "epoch: 141  loss: 0.20048389  acc: 0.96666664\n",
            "epoch: 151  loss: 0.19702847  acc: 0.96666664\n",
            "epoch: 161  loss: 0.19369666  acc: 0.96666664\n",
            "epoch: 171  loss: 0.19048271  acc: 0.96666664\n",
            "epoch: 181  loss: 0.18738127  acc: 0.96666664\n",
            "epoch: 191  loss: 0.18438716  acc: 0.96666664\n",
            "epoch: 201  loss: 0.18149552  acc: 0.96666664\n",
            "epoch: 211  loss: 0.17870173  acc: 0.96666664\n",
            "epoch: 221  loss: 0.17600146  acc: 0.96666664\n",
            "epoch: 231  loss: 0.17339058  acc: 0.96666664\n",
            "epoch: 241  loss: 0.17086510  acc: 0.96666664\n",
            "epoch: 251  loss: 0.16842134  acc: 0.96666664\n",
            "epoch: 261  loss: 0.16605574  acc: 0.96666664\n",
            "epoch: 271  loss: 0.16376491  acc: 0.96666664\n",
            "epoch: 281  loss: 0.16154571  acc: 0.96666664\n",
            "epoch: 291  loss: 0.15939508  acc: 0.96666664\n",
            "TOTAL TRAINING TIME: 0.3892545700073242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiywgvRkCyfg",
        "outputId": "b05fc0ab-3430-480e-b76d-6661696eaeab"
      },
      "source": [
        "_, preds = torch.max(y_pred, dim=1) #y_pred devuelve probabilidades y predicciones, solo nos interesa preds\n",
        "print(f'Aciertos: {torch.sum(preds == y_train).item()}')\n",
        "print(f'Muestras totales: {len(preds)}')\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aciertos: 116\n",
            "Muestras totales: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSeKhoB3eq-h",
        "outputId": "ca5dc023-666b-4f2e-eca8-fa25b9d3a896"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 2, 0, 1,\n",
            "        2, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1,\n",
            "        2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 1, 0,\n",
            "        1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 1, 0, 0, 2,\n",
            "        1, 1, 0, 1, 1, 0, 2, 2, 2, 1, 2, 0, 1, 0, 0, 0, 2, 1, 2, 1, 2, 1, 2, 0],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-UUtvDCevXg",
        "outputId": "eca7a0d3-cf2b-4a6d-b16b-e8633c52f34b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 2, 0, 1,\n",
            "        2, 2, 1, 1, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 0, 1, 2, 1,\n",
            "        2, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 1, 0,\n",
            "        1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 1, 0, 0, 1,\n",
            "        1, 1, 0, 1, 1, 0, 2, 2, 2, 1, 2, 0, 1, 0, 0, 0, 2, 1, 2, 1, 2, 1, 2, 0],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laOv0FJc3xJW"
      },
      "source": [
        "# Curiosidad: Volviendo a CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFW2KUGA33Fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae838f40-ba76-45f3-bc9a-09e6e0278203"
      },
      "source": [
        "torch.manual_seed(32)\n",
        "model2 = Model()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\n",
        "\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
        "testloader = DataLoader(X_test, batch_size=60, shuffle=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "import time\n",
        "epochs = 300\n",
        "losses = []\n",
        "start = time.time()\n",
        "for i in range(epochs):\n",
        "    i+=1\n",
        "    y_pred = model2(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    losses.append(loss)\n",
        "    \n",
        "    # a neat trick to save screen space:\n",
        "    if i%10 == 1:\n",
        "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "print(f'TOTAL TRAINING TIME: {time.time()-start}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1  loss: 1.90774035\n",
            "epoch: 11  loss: 1.90774035\n",
            "epoch: 21  loss: 1.90774035\n",
            "epoch: 31  loss: 1.90774035\n",
            "epoch: 41  loss: 1.90774035\n",
            "epoch: 51  loss: 1.90774035\n",
            "epoch: 61  loss: 1.90774035\n",
            "epoch: 71  loss: 1.90774035\n",
            "epoch: 81  loss: 1.90774035\n",
            "epoch: 91  loss: 1.90774035\n",
            "epoch: 101  loss: 1.90774035\n",
            "epoch: 111  loss: 1.90774035\n",
            "epoch: 121  loss: 1.90774035\n",
            "epoch: 131  loss: 1.90774035\n",
            "epoch: 141  loss: 1.90774035\n",
            "epoch: 151  loss: 1.90774035\n",
            "epoch: 161  loss: 1.90774035\n",
            "epoch: 171  loss: 1.90774035\n",
            "epoch: 181  loss: 1.90774035\n",
            "epoch: 191  loss: 1.90774035\n",
            "epoch: 201  loss: 1.90774035\n",
            "epoch: 211  loss: 1.90774035\n",
            "epoch: 221  loss: 1.90774035\n",
            "epoch: 231  loss: 1.90774035\n",
            "epoch: 241  loss: 1.90774035\n",
            "epoch: 251  loss: 1.90774035\n",
            "epoch: 261  loss: 1.90774035\n",
            "epoch: 271  loss: 1.90774035\n",
            "epoch: 281  loss: 1.90774035\n",
            "epoch: 291  loss: 1.90774035\n",
            "TOTAL TRAINING TIME: 0.2914440631866455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2QOf-HEltUP"
      },
      "source": [
        "## Fin del Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDr1zYmBkRV"
      },
      "source": [
        "Referencias y modelos empleados para el Notebook: \n",
        "\n",
        "*   Documentación de [Pytorch](https://pytorch.org/docs/stable/index.html) \n",
        "*   [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi\n",
        "*   [FastAI](https://www.fast.ai/) development notebooks by Jeremy Howard.\n",
        "*   Documentación y cursos en [Pierian Data](https://www.pieriandata.com/)\n",
        "*   Tutoriales y notebooks del curso \"Deep Learning with Pytorch: Zero to GANs\" de [Aakash N S](https://jovian.ai/aakashns)\n",
        "* [A visual proof that neural networks can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html), también conocido como Teorema de Aproximación Universal\n",
        "* [But what *is* a neural network?](https://www.youtube.com/watch?v=aircAruvnKk) - Una introducción muy intuitiva a lo que son las redes neuronales y lo que implican las capas ocultas."
      ]
    }
  ]
}